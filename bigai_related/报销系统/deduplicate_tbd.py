#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tbdæ–‡ä»¶å¤¹å»é‡å·¥å…·
åŠŸèƒ½ï¼š
1. æ£€æŸ¥tbdæ–‡ä»¶å¤¹ä¸­å…·æœ‰ç›¸åŒå‘ç¥¨å·ç çš„é‡å¤æ–‡ä»¶
2. ä¿ç•™ä¸€ä¸ªæ–‡ä»¶ï¼Œåˆ é™¤å…¶ä»–é‡å¤æ–‡ä»¶
3. ç”Ÿæˆå»é‡æŠ¥å‘Š
"""

import os
import re
import shutil
import hashlib
import fitz  # PyMuPDF
import pytesseract
from PIL import Image
import io
import logging
from pathlib import Path
from typing import Set, Dict, List, Optional, Tuple
from collections import defaultdict

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

class TBDDeduplicator:
    """TBDæ–‡ä»¶å¤¹å»é‡å™¨"""

    def __init__(self):
        """åˆå§‹åŒ–å»é‡å™¨"""
        self.base_path = "/Users/lr-2002/Documents/æŠ¥é”€ææ–™/"
        self.tbd_folder = os.path.join(self.base_path, "tbd")
        self.duplicates_folder = os.path.join(self.tbd_folder, "duplicates")

        # åˆ›å»ºduplicatesæ–‡ä»¶å¤¹å­˜æ”¾é‡å¤æ–‡ä»¶
        Path(self.duplicates_folder).mkdir(parents=True, exist_ok=True)

        # å‘ç¥¨å·ç çš„æ­£åˆ™è¡¨è¾¾å¼æ¨¡å¼
        self.invoice_number_patterns = [
            r"å‘ç¥¨å·ç [ï¼š:](\d{8,})",
            r"å‘ç¥¨ä»£ç [ï¼š:]?(\d{10,12})",
            r"No[.:]?\s*(\d{8,})",
            r"(\d{20,})",
        ]

    def get_file_hash(self, file_path: str) -> str:
        """è®¡ç®—æ–‡ä»¶çš„MD5å“ˆå¸Œå€¼"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def extract_text_from_pdf(self, pdf_path: str) -> str:
        """ä»PDFä¸­æå–æ–‡æœ¬"""
        try:
            doc = fitz.open(pdf_path)
            text = ""
            for page in doc:
                text += page.get_text()
            doc.close()
            return text
        except Exception as e:
            logger.error(f"PDFæ–‡æœ¬æå–å¤±è´¥ {pdf_path}: {e}")
            return ""

    def pdf_to_image_ocr(self, pdf_path: str) -> str:
        """å°†PDFè½¬æ¢ä¸ºå›¾åƒå¹¶è¿›è¡ŒOCRè¯†åˆ«"""
        try:
            doc = fitz.open(pdf_path)
            text = ""

            for page_num in range(len(doc)):
                page = doc.load_page(page_num)
                # å°†é¡µé¢è½¬æ¢ä¸ºå›¾åƒ
                pix = page.get_pixmap(matrix=fitz.Matrix(2, 2))  # æé«˜åˆ†è¾¨ç‡
                img_data = pix.tobytes("png")
                img = Image.open(io.BytesIO(img_data))

                # ä½¿ç”¨OCRè¯†åˆ«
                ocr_text = pytesseract.image_to_string(img, lang="chi_sim+eng")
                text += ocr_text + "\n"

            doc.close()
            return text
        except Exception as e:
            logger.error(f"OCRè¯†åˆ«å¤±è´¥ {pdf_path}: {e}")
            return ""

    def extract_invoice_numbers_from_text(self, text: str) -> List[str]:
        """ä»æ–‡æœ¬ä¸­æå–å‘ç¥¨å·ç """
        numbers = []
        for pattern in self.invoice_number_patterns:
            matches = re.findall(pattern, text)
            for match in matches:
                if len(match) >= 8:  # å‘ç¥¨å·ç é€šå¸¸è‡³å°‘8ä½
                    numbers.append(match)
        return numbers

    def extract_invoice_numbers_from_pdf(self, pdf_path: str) -> List[str]:
        """ä»å•ä¸ªPDFæ–‡ä»¶ä¸­æå–å‘ç¥¨å·ç """
        logger.info(f"æ­£åœ¨å¤„ç†: {os.path.basename(pdf_path)}")

        # é¦–å…ˆå°è¯•ç›´æ¥æå–æ–‡æœ¬
        text = self.extract_text_from_pdf(pdf_path)

        # å¦‚æœæ–‡æœ¬æå–æ•ˆæœä¸å¥½ï¼Œä½¿ç”¨OCR
        if len(text.strip()) < 100:  # æ–‡æœ¬å¤ªå°‘ï¼Œå¯èƒ½éœ€è¦OCR
            logger.info(f"æ–‡æœ¬æå–ä¸è¶³ï¼Œä½¿ç”¨OCR: {os.path.basename(pdf_path)}")
            text = self.pdf_to_image_ocr(pdf_path)

        if text.strip():
            return self.extract_invoice_numbers_from_text(text)
        else:
            logger.warning(f"æ— æ³•ä» {os.path.basename(pdf_path)} ä¸­æå–æ–‡æœ¬")
            return []

    def get_tbd_pdf_files(self) -> List[str]:
        """è·å–tbdæ–‡ä»¶å¤¹ä¸­çš„æ‰€æœ‰PDFæ–‡ä»¶ï¼ˆæ’é™¤doneå’Œduplicatesæ–‡ä»¶å¤¹ï¼‰"""
        tbd_path = Path(self.tbd_folder)
        excluded_folders = ['done', 'duplicates']

        pdf_files = []
        for pdf_file in tbd_path.glob("*.pdf"):
            exclude = False
            for folder in excluded_folders:
                excluded_path = tbd_path / folder
                try:
                    if pdf_file.resolve().is_relative_to(excluded_path.resolve()):
                        exclude = True
                        break
                except AttributeError:
                    # Python < 3.9 æ²¡æœ‰ is_relative_to æ–¹æ³•
                    if str(pdf_file.resolve()).startswith(str(excluded_path.resolve())):
                        exclude = True
                        break

            if not exclude:
                pdf_files.append(str(pdf_file))

        return sorted(pdf_files)

    def find_duplicates(self) -> Dict:
        """
        æŸ¥æ‰¾é‡å¤æ–‡ä»¶

        Returns:
            åŒ…å«é‡å¤æ–‡ä»¶ä¿¡æ¯çš„å­—å…¸
        """
        logger.info("å¼€å§‹æŸ¥æ‰¾tbdæ–‡ä»¶å¤¹ä¸­çš„é‡å¤æ–‡ä»¶...")

        pdf_files = self.get_tbd_pdf_files()

        if not pdf_files:
            logger.info("tbdæ–‡ä»¶å¤¹ä¸­æ²¡æœ‰PDFæ–‡ä»¶")
            return {
                'total_files': 0,
                'files_with_invoices': 0,
                'duplicate_groups': [],
                'exact_duplicates': [],
                'no_invoice_files': []
            }

        logger.info(f"æ‰¾åˆ° {len(pdf_files)} ä¸ªPDFæ–‡ä»¶")

        # æŒ‰å‘ç¥¨å·ç åˆ†ç»„
        invoice_to_files = defaultdict(list)
        # æŒ‰æ–‡ä»¶å“ˆå¸Œåˆ†ç»„ï¼ˆç”¨äºæŸ¥æ‰¾å®Œå…¨ç›¸åŒçš„æ–‡ä»¶ï¼‰
        hash_to_files = defaultdict(list)

        results = {
            'total_files': len(pdf_files),
            'files_with_invoices': 0,
            'duplicate_groups': [],
            'exact_duplicates': [],
            'no_invoice_files': []
        }

        # å¤„ç†æ¯ä¸ªæ–‡ä»¶
        for pdf_file in pdf_files:
            try:
                # è®¡ç®—æ–‡ä»¶å“ˆå¸Œ
                file_hash = self.get_file_hash(pdf_file)
                hash_to_files[file_hash].append(pdf_file)

                # æå–å‘ç¥¨å·ç 
                invoice_numbers = self.extract_invoice_numbers_from_pdf(pdf_file)

                if invoice_numbers:
                    results['files_with_invoices'] += 1
                    for invoice_number in invoice_numbers:
                        invoice_to_files[invoice_number].append(pdf_file)
                else:
                    results['no_invoice_files'].append(pdf_file)
                    logger.warning(f"æ–‡ä»¶ {os.path.basename(pdf_file)} ä¸­æœªæ‰¾åˆ°å‘ç¥¨å·ç ")

            except Exception as e:
                logger.error(f"å¤„ç†æ–‡ä»¶ {os.path.basename(pdf_file)} æ—¶å‡ºé”™: {e}")

        # æŸ¥æ‰¾å‘ç¥¨å·ç é‡å¤çš„æ–‡ä»¶
        for invoice_number, files in invoice_to_files.items():
            if len(files) > 1:
                # åˆ›å»ºé‡å¤ç»„ä¿¡æ¯
                duplicate_group = {
                    'invoice_number': invoice_number,
                    'files': []
                }

                for file_path in files:
                    file_info = {
                        'path': file_path,
                        'name': os.path.basename(file_path),
                        'size': os.path.getsize(file_path),
                        'hash': self.get_file_hash(file_path),
                        'modified': os.path.getmtime(file_path)
                    }
                    duplicate_group['files'].append(file_info)

                # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œæœ€æ–°çš„æ–‡ä»¶æ’åœ¨å‰é¢
                duplicate_group['files'].sort(key=lambda x: x['modified'], reverse=True)

                results['duplicate_groups'].append(duplicate_group)

        # æŸ¥æ‰¾å®Œå…¨ç›¸åŒçš„æ–‡ä»¶
        for file_hash, files in hash_to_files.items():
            if len(files) > 1:
                exact_duplicate = {
                    'hash': file_hash,
                    'files': [os.path.basename(f) for f in files],
                    'paths': files
                }
                results['exact_duplicates'].append(exact_duplicate)

        return results

    def select_file_to_keep(self, files: List[Dict]) -> Dict:
        """
        é€‰æ‹©è¦ä¿ç•™çš„æ–‡ä»¶

        Args:
            files: æ–‡ä»¶ä¿¡æ¯åˆ—è¡¨

        Returns:
            è¦ä¿ç•™çš„æ–‡ä»¶ä¿¡æ¯
        """
        # é€‰æ‹©æœ€æ–°çš„æ–‡ä»¶ä½œä¸ºä¸»æ–‡ä»¶
        return files[0]  # å·²ç»æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åˆ—

    def deduplicate_files(self, dry_run: bool = False) -> Dict:
        """
        æ‰§è¡Œå»é‡æ“ä½œ

        Args:
            dry_run: æ˜¯å¦ä¸ºæ¼”ç»ƒæ¨¡å¼

        Returns:
            å¤„ç†ç»“æœ
        """
        # æŸ¥æ‰¾é‡å¤æ–‡ä»¶
        duplicate_results = self.find_duplicates()

        if not duplicate_results['duplicate_groups'] and not duplicate_results['exact_duplicates']:
            logger.info("æ²¡æœ‰å‘ç°é‡å¤æ–‡ä»¶")
            return {
                'duplicate_groups_processed': 0,
                'files_deleted': 0,
                'exact_duplicates_processed': 0,
                'errors': []
            }

        results = {
            'duplicate_groups_processed': 0,
            'files_deleted': 0,
            'exact_duplicates_processed': 0,
            'deleted_files': [],
            'kept_files': [],
            'errors': []
        }

        # å¤„ç†å‘ç¥¨å·ç é‡å¤çš„æ–‡ä»¶
        for group in duplicate_results['duplicate_groups']:
            try:
                files = group['files']
                invoice_number = group['invoice_number']

                logger.info(f"å¤„ç†å‘ç¥¨å·ç  {invoice_number} çš„é‡å¤æ–‡ä»¶:")
                for file_info in files:
                    logger.info(f"  - {file_info['name']} ({file_info['size']} bytes)")

                # é€‰æ‹©è¦ä¿ç•™çš„æ–‡ä»¶
                file_to_keep = self.select_file_to_keep(files)
                files_to_delete = [f for f in files if f['hash'] != file_to_keep['hash']]

                # å¦‚æœæ‰€æœ‰æ–‡ä»¶éƒ½ä¸åŒï¼ˆåªæ˜¯å‘ç¥¨å·ç ç›¸åŒï¼‰ï¼Œä¿ç•™æœ€æ–°çš„ï¼Œç§»åŠ¨å…¶ä»–çš„
                if not files_to_delete:
                    files_to_delete = files[1:]  # ä¿ç•™ç¬¬ä¸€ä¸ªï¼Œåˆ é™¤å…¶ä½™çš„

                logger.info(f"ä¿ç•™: {file_to_keep['name']}")
                logger.info(f"å°†è¦ç§»åŠ¨çš„é‡å¤æ–‡ä»¶: {len(files_to_delete)} ä¸ª")

                results['kept_files'].append(file_to_keep['path'])

                # ç§»åŠ¨é‡å¤æ–‡ä»¶
                for file_info in files_to_delete:
                    file_path = file_info['path']
                    file_name = file_info['name']
                    target_path = os.path.join(self.duplicates_folder, f"{invoice_number}_{file_name}")

                    if not dry_run:
                        shutil.move(file_path, target_path)
                        logger.info(f"å·²ç§»åŠ¨: {file_name} -> duplicates/{invoice_number}_{file_name}")

                    results['deleted_files'].append({
                        'original_path': file_path,
                        'target_path': target_path,
                        'invoice_number': invoice_number,
                        'reason': 'å‘ç¥¨å·ç é‡å¤'
                    })
                    results['files_deleted'] += 1

                results['duplicate_groups_processed'] += 1

            except Exception as e:
                error_msg = f"å¤„ç†å‘ç¥¨å·ç  {group.get('invoice_number', 'unknown')} çš„é‡å¤æ–‡ä»¶æ—¶å‡ºé”™: {e}"
                logger.error(error_msg)
                results['errors'].append(error_msg)

        # å¤„ç†å®Œå…¨ç›¸åŒçš„æ–‡ä»¶
        for exact_group in duplicate_results['exact_duplicates']:
            try:
                files = exact_group['paths']
                file_name = exact_group['files'][0]  # æ‰€æœ‰æ–‡ä»¶ååº”è¯¥ç›¸åŒ

                if len(files) <= 1:
                    continue

                logger.info(f"å¤„ç†å®Œå…¨ç›¸åŒçš„æ–‡ä»¶: {file_name}")
                for file_path in files:
                    logger.info(f"  - {file_path}")

                # ä¿ç•™ç¬¬ä¸€ä¸ªæ–‡ä»¶ï¼Œç§»åŠ¨å…¶ä½™çš„
                file_to_keep = files[0]
                files_to_delete = files[1:]

                logger.info(f"ä¿ç•™: {file_to_keep}")

                results['kept_files'].append(file_to_keep)

                # ç§»åŠ¨å®Œå…¨ç›¸åŒçš„æ–‡ä»¶
                for i, file_path in enumerate(files_to_delete, 1):
                    base_name, ext = os.path.splitext(file_name)
                    target_name = f"{base_name}_duplicate_{i}{ext}"
                    target_path = os.path.join(self.duplicates_folder, target_name)

                    if not dry_run:
                        shutil.move(file_path, target_path)
                        logger.info(f"å·²ç§»åŠ¨: {os.path.basename(file_path)} -> duplicates/{target_name}")

                    results['deleted_files'].append({
                        'original_path': file_path,
                        'target_path': target_path,
                        'reason': 'æ–‡ä»¶å®Œå…¨ç›¸åŒ'
                    })
                    results['files_deleted'] += 1

                results['exact_duplicates_processed'] += 1

            except Exception as e:
                error_msg = f"å¤„ç†å®Œå…¨ç›¸åŒçš„æ–‡ä»¶æ—¶å‡ºé”™: {e}"
                logger.error(error_msg)
                results['errors'].append(error_msg)

        return results

    def generate_report(self, duplicate_results: Dict, dedup_results: Dict) -> None:
        """ç”Ÿæˆè¯¦ç»†æŠ¥å‘Š"""
        print("\n" + "="*60)
        print("ğŸ” TBDæ–‡ä»¶å¤¹é‡å¤æ–‡ä»¶æ£€æŸ¥æŠ¥å‘Š")
        print("="*60)

        print(f"\nğŸ“Š æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  æ€»æ–‡ä»¶æ•°: {duplicate_results['total_files']}")
        print(f"  åŒ…å«å‘ç¥¨å·ç çš„æ–‡ä»¶: {duplicate_results['files_with_invoices']}")
        print(f"  æ— å‘ç¥¨å·ç çš„æ–‡ä»¶: {len(duplicate_results['no_invoice_files'])}")

        print(f"\nğŸ”„ é‡å¤æ–‡ä»¶ç»Ÿè®¡:")
        print(f"  å‘ç¥¨å·ç é‡å¤ç»„æ•°: {len(duplicate_results['duplicate_groups'])}")
        print(f"  å®Œå…¨ç›¸åŒçš„æ–‡ä»¶ç»„æ•°: {len(duplicate_results['exact_duplicates'])}")

        if duplicate_results['duplicate_groups']:
            print(f"\nğŸ“‹ å‘ç¥¨å·ç é‡å¤è¯¦æƒ…:")
            for i, group in enumerate(duplicate_results['duplicate_groups'], 1):
                invoice_number = group['invoice_number']
                files = group['files']
                print(f"  {i}. å‘ç¥¨å·ç : {invoice_number}")
                print(f"     é‡å¤æ–‡ä»¶æ•°: {len(files)}")
                for j, file_info in enumerate(files, 1):
                    size_mb = file_info['size'] / (1024*1024)
                    modified_time = __import__('datetime').datetime.fromtimestamp(file_info['modified'])
                    print(f"     {j}. {file_info['name']}")
                    print(f"        å¤§å°: {size_mb:.2f} MB, ä¿®æ”¹æ—¶é—´: {modified_time.strftime('%Y-%m-%d %H:%M:%S')}")

        if duplicate_results['exact_duplicates']:
            print(f"\nğŸ“‹ å®Œå…¨ç›¸åŒçš„æ–‡ä»¶:")
            for i, group in enumerate(duplicate_results['exact_duplicates'], 1):
                file_hash = group['hash'][:8]  # åªæ˜¾ç¤ºå‰8ä½
                files = group['files']
                print(f"  {i}. å“ˆå¸Œ {file_hash}...: {len(files)} ä¸ªç›¸åŒæ–‡ä»¶")
                for file_name in files:
                    print(f"     - {file_name}")

        print(f"\nğŸ—‘ï¸ å»é‡æ“ä½œç»“æœ:")
        print(f"  å¤„ç†çš„å‘ç¥¨é‡å¤ç»„æ•°: {dedup_results['duplicate_groups_processed']}")
        print(f"  å¤„ç†çš„å®Œå…¨ç›¸åŒç»„æ•°: {dedup_results['exact_duplicates_processed']}")
        print(f"  ç§»åŠ¨çš„æ–‡ä»¶æ•°é‡: {dedup_results['files_deleted']}")
        print(f"  ä¿ç•™çš„æ–‡ä»¶æ•°é‡: {len(dedup_results['kept_files'])}")

        if dedup_results['errors']:
            print(f"\nâŒ é”™è¯¯ä¿¡æ¯:")
            for i, error in enumerate(dedup_results['errors'], 1):
                print(f"  {i}. {error}")

        print(f"\n" + "="*60)

def main():
    """ä¸»å‡½æ•°"""
    import argparse

    parser = argparse.ArgumentParser(description="æ£€æŸ¥å¹¶æ¸…ç†tbdæ–‡ä»¶å¤¹ä¸­çš„é‡å¤æ–‡ä»¶")
    parser.add_argument("--dry-run", action='store_true',
                       help="æ¼”ç»ƒæ¨¡å¼ï¼Œåªæ£€æŸ¥ä¸ç§»åŠ¨æ–‡ä»¶")

    args = parser.parse_args()

    # åˆ›å»ºå»é‡å™¨
    deduplicator = TBDDeduplicator()

    print("ğŸ” å¼€å§‹æ£€æŸ¥tbdæ–‡ä»¶å¤¹ä¸­çš„é‡å¤æ–‡ä»¶...")
    print(f"ğŸ“ TBDæ–‡ä»¶å¤¹: {deduplicator.tbd_folder}")
    print(f"ğŸ“ Duplicatesæ–‡ä»¶å¤¹: {deduplicator.duplicates_folder}")

    if args.dry_run:
        print("ğŸ§ª æ¼”ç»ƒæ¨¡å¼ - ä¸ä¼šå®é™…ç§»åŠ¨æ–‡ä»¶")
    else:
        print("ğŸš€ æ­£å¼æ¨¡å¼ - å°†ç§»åŠ¨é‡å¤æ–‡ä»¶")

    print()

    # æŸ¥æ‰¾é‡å¤æ–‡ä»¶
    duplicate_results = deduplicator.find_duplicates()

    # ç”Ÿæˆæ£€æŸ¥æŠ¥å‘Š
    deduplicator.generate_report(duplicate_results, {'duplicate_groups_processed': 0, 'files_deleted': 0, 'exact_duplicates_processed': 0, 'kept_files': [], 'errors': []})

    # å¦‚æœæ²¡æœ‰é‡å¤æ–‡ä»¶ï¼Œç›´æ¥é€€å‡º
    if not duplicate_results['duplicate_groups'] and not duplicate_results['exact_duplicates']:
        print("âœ… æ²¡æœ‰å‘ç°é‡å¤æ–‡ä»¶ï¼Œæ— éœ€å¤„ç†ã€‚")
        return

    # è¯¢é—®æ˜¯å¦ç»§ç»­
    if args.dry_run:
        print("\nğŸ§ª æ¼”ç»ƒæ¨¡å¼å®Œæˆï¼Œä»¥ä¸Šä¸ºæ£€æŸ¥ç»“æœã€‚")
        return

    print("\nâ“ æ˜¯å¦ç»§ç»­æ‰§è¡Œå»é‡æ“ä½œï¼Ÿ(y/N): ", end="")
    response = input().strip().lower()

    if response not in ['y', 'yes']:
        print("âŒ ç”¨æˆ·å–æ¶ˆæ“ä½œã€‚")
        return

    # æ‰§è¡Œå»é‡
    print("\nğŸ”„ å¼€å§‹æ‰§è¡Œå»é‡æ“ä½œ...")
    dedup_results = deduplicator.deduplicate_files(dry_run=False)

    # ç”Ÿæˆæœ€ç»ˆæŠ¥å‘Š
    print("\n" + "="*60)
    print("ğŸ‰ å»é‡æ“ä½œå®Œæˆï¼")
    deduplicator.generate_report(duplicate_results, dedup_results)

if __name__ == "__main__":
    main()